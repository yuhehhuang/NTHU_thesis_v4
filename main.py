import os
import copy
import pandas as pd
from src.init import load_system_data
from src.greedy import run_greedy_per_W, run_greedy_path_for_user
from src.hungarian import run_hungarian_per_W
from src.utils import recompute_all_data_rates
from src.dp import run_dp_per_W
from src.dp_opti import run_batch_optimal_dp_per_W
from src.ga import GeneticAlgorithm  
from src.mslb import run_mslb_batch
from src.hungarian_new import run_hungarian_new_per_W
import time
from datetime import datetime
# === æ–¹æ³•é¸æ“‡ ===
METHOD = "greedy"  # å¯é¸:dp ,greedy ,ga ,mslb,hungarian  ############ä½ è¦æ‰‹å‹•è¨­å®š##############################
# æŒ‡å®šè¦ä½¿ç”¨å“ªçµ„ user æª” (ä¾‹å¦‚ 125 -> data/user_info125.csv)
USER_NUM = 100                     ############ä½ è¦æ‰‹å‹•è¨­å®š##############################
user_csv = f"data/user_info{USER_NUM}.csv"
# === 1ï¸âƒ£ è¼‰å…¥ç³»çµ±è³‡æ–™ ===
system = load_system_data(regenerate_sat_channels=False, user_csv_path=user_csv)
df_users = system["users"]
df_access = system["access_matrix"]
path_loss = system["path_loss"]
params = system["params"]
sat_channel_dict_backup = system["sat_channel_dict_backup"]
sat_positions = system["sat_positions"]

# è¨­å®š W èˆ‡ alpha
W = 2  ############ä½ è¦æ‰‹å‹•è¨­å®š##############################
alpha = params["alpha"]  ############ä½ è¦æ‰‹å‹•è¨­å®š,å»src/parameter.pyè¨­å®š##############################

# === 2ï¸âƒ£ åŸ·è¡Œå°æ‡‰çš„æ–¹æ³• ===
method_start = time.perf_counter()  
if METHOD == "greedy":
    results_df, all_user_paths, load_by_time, df_data_rates = run_greedy_per_W(
        user_df=df_users,
        access_matrix=df_access.to_dict(orient="records"),
        path_loss=path_loss,
        sat_load_dict_backup=copy.deepcopy(sat_channel_dict_backup),
        params=params,
        W=W
    )
elif METHOD == "hungarian":
    results_df, all_user_paths, load_by_time = run_hungarian_per_W(
        df_users=df_users,
        df_access=df_access,
        path_loss=path_loss,
        sat_channel_dict_backup=copy.deepcopy(sat_channel_dict_backup),
        sat_positions=sat_positions,
        params=params,
        W=W
    )
    df_data_rates = results_df.copy()
elif METHOD == "dp":
    results_df, all_user_paths, load_by_time, df_data_rates = run_dp_per_W(
        user_df=df_users,
        access_matrix=df_access.to_dict(orient="records"),
        path_loss=path_loss,
        sat_load_dict_backup=copy.deepcopy(sat_channel_dict_backup),
        params=params,
        W=W
    )
elif METHOD == "ga":
    ga = GeneticAlgorithm(
        population_size=10,
        user_df=df_users,
        access_matrix=df_access.to_dict(orient="records"),
        W=W,
        path_loss=path_loss,
        sat_channel_dict=copy.deepcopy(sat_channel_dict_backup),
        params=params,
        seed=123456  # âœ… å›ºå®šä¸€å€‹æ•´æ•¸ seedï¼›ä¸æƒ³å›ºå®šå°±æ‹¿æ‰é€™è¡Œ
    )
    ga.evolve(generations=5)  # è¨“ç·´ 5 è¼ª(5è¼ªå¤§æ¦‚è¦1å°æ™‚)ï¼Œå¯èª¿æ•´ç‚º 20ã€50 ç­‰ç­‰
    results_df, all_user_paths, load_by_time, df_data_rates = ga.export_best_result()
elif METHOD == "mslb":
    results_df, all_user_paths, load_by_time, df_data_rates = run_mslb_batch(
        user_df=df_users,
        access_matrix=df_access.to_dict(orient="records"),
        path_loss=path_loss,
        sat_channel_dict=copy.deepcopy(sat_channel_dict_backup),
        params=params,
        W=W
    )
else:
    raise ValueError(f"æœªçŸ¥çš„ METHOD: {METHOD}")
method_elapsed = time.perf_counter() - method_start 
# === 3ï¸âƒ£ é‡æ–°è¨ˆç®—æ­£ç¢ºçš„ data rateï¼ˆè€ƒæ…®æ‰€æœ‰å¹²æ“¾ï¼‰===
if isinstance(all_user_paths, pd.DataFrame):
    user_path_records = all_user_paths.to_dict(orient="records")
else:
    user_path_records = all_user_paths

df_correct_rates = recompute_all_data_rates(
    user_path_records, path_loss, params, sat_channel_dict_backup
)

# èˆ‡åŸæœ¬ data rate å°é½Šæ’åº
df_correct_rates = df_correct_rates.set_index(["user_id", "time"]).reindex(
    df_data_rates.set_index(["user_id", "time"]).index
).reset_index()

# === 4ï¸âƒ£ å»ºç«‹ results è³‡æ–™å¤¾ ===
os.makedirs("results", exist_ok=True)
timing_row = {
    "timestamp": datetime.now().isoformat(timespec="seconds"),
    "method": METHOD,
    "W": int(W),
    "alpha": float(alpha),
    "elapsed_sec": round(method_elapsed, 6),
    "num_users": int(len(df_users)),
    "num_time_slots": int(len(df_access)),
}
timing_path = "results/method_timings.csv"
write_header = not os.path.exists(timing_path)
pd.DataFrame([timing_row]).to_csv(
    timing_path, mode="a", header=write_header, index=False
)
# === 5ï¸âƒ£ å„²å­˜çµæœ ===
prefix = f"{METHOD}_W{W}_users{USER_NUM}_alpha{alpha}"
results_df.to_csv(f"results/{prefix}_results.csv", index=False)
pd.DataFrame(all_user_paths).to_csv(f"results/{prefix}_paths.csv", index=False)
df_data_rates.to_csv(f"results/{prefix}_data_rates.csv", index=False)

# === 6ï¸âƒ£ è¼¸å‡º Load ç‹€æ…‹ï¼ˆå« initial éš¨æ©Ÿ loadï¼‰===
records = []
df_access = df_access.reset_index(drop=True)
for t in range(len(df_access)):
    visible_sats = df_access.loc[t, "visible_sats"]
    for sat in visible_sats:
        assigned_load = load_by_time[t].get(sat, 0)
        random_load = sum(sat_channel_dict_backup[sat].values()) if sat in sat_channel_dict_backup else 0
        total_load = assigned_load + random_load
        records.append({"time": t, "sat": sat, "load": total_load})
df_load = pd.DataFrame(records)
df_load.to_csv(f"results/{prefix}_load_by_time.csv", index=False)

# === 7ï¸âƒ£ è¼¸å‡ºæ­£ç¢º data rateï¼ˆé‡æ–°è¨ˆç®—å¹²æ“¾ï¼‰===
df_correct_rates.to_csv(f"results/{prefix}_real_data_rates.csv", index=False)

# === 8ï¸âƒ£ å®Œæˆè¨Šæ¯ ===
print(f"\nâœ… {METHOD.upper()} æ–¹æ³•å®Œæˆï¼")
print(f"ğŸ“„ çµæœå·²å„²å­˜è‡³ results/{prefix}_results.csv")
print(f"ğŸ“„ è·¯å¾‘å·²å„²å­˜è‡³ results/{prefix}_paths.csv")
print(f"ğŸ“„ Data Rateï¼ˆç•¶ä¸‹åˆ†é…ï¼‰å·²å„²å­˜è‡³ results/{prefix}_data_rates.csv")
print(f"ğŸ“„ Load ç‹€æ…‹å·²å„²å­˜è‡³ results/{prefix}_load_by_time.csv")
print(f"ğŸ“„ Data Rateï¼ˆé‡æ–°è¨ˆç®—å¹²æ“¾ï¼‰å·²å„²å­˜è‡³ results/{prefix}_real_data_rates.csv")
